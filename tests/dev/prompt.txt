# prompt.txt

（一）BERT

- 路径优化：
  - 从file_path取和存BERT标记好的文件，保证这些文件名不和原BERT处理的文件名重名
  - 这些文件存储到../data/ft_data/labelled路径下，合拢为"all_labelled.txt"，存同个文件夹
  - 合拢中，请你根据每个数据集的抽取贴吧名字，例如：
    - 'tp_yuanshen_tp_ft_trunc500000_labeled'来源于'yuanshen'，贴吧名为'yuanshen'
    - 'pc_aiouniya_pc_ft_trunc0_labeled'来源于'aiouniya'，贴吧名为'aiouniya'
  - 另外一个就是数据的来源'source'，也抽取，例如：
    - 'tp_yuanshen_tp_ft_trunc500000_labeled'对应的是'tp'，来源就是'tp'
    - 'pc_aiouniya_pc_ft_trunc0_labeled'对应的是'pc'，来源就是'pc'
  - 贴吧名字这列是'tieba_name'，然后数据来源是'source'，抽取之后是作为新的两列加入合拢的数据集
  - 文件的列数和源文件all_labelled.txt一样是六列，仅仅是行数区别
- 仍然在ft_all_n.py中，两个任务代码单独展开实现，去生成第二个任务用的代码，
  - 

- 工程改进：

  - 现在有三个主
  - 现有两个主要流程
  - BERT的数据初始化
  - 加入断点处理的逻辑
  - 自迭代产生的标签分布没有明显变化
  - 现在请集中你的embeddings给出第一个任务回答。
  - 自迭代超参数每一次调流程只使用了一次，应扩展

  - 请据此增加或修改原代码，部署FastText有监督训练及自迭代。
  - 相比一次性加载完整的数据加载，分批效果尚不明显，需要替代方案
  - 因为只有8gb的intel uhd内存，请你将all_labelled.txt转换成Dask格式

  - 然后不采用分批加载，而是压缩加载到内存上的，用训练好的fasttext去预测标签

  - 参数微调：
（1）通过修改nvidia 4070的显卡配置，动态调整显存的调度
（2）尝试部署一套模型剪枝和量化的参数集，用于NSP模型的推理及加速
（3）调低BERT的NSP模型的学习率和ngrams，scaler混合使用MinMaxScaler和GradScaler
（4）在不做外扩的前提下，从"内存优化", "异步处理和批量处理"和"增加虚拟内存"中选择一个机制，优化模型实时推理的代码

  - 模型训练、预测以及参数微调：
  - 通过修改nvidia 4070的显卡配置，动态调整显存的调度
  - 尝试部署一套模型剪枝和量化的参数集，用于NSP模型的推理及加速
（3）调低BERT的NSP模型的学习率和ngrams，scaler混合使用MinMaxScaler和GradScaler
（4）在不做外扩的前提下，从"内存优化", "异步处理和批量处理"和"增加虚拟内存"中选择一个机制，优化模型实时推理的代码
  - 工程改进：加入断点处理的逻辑

- 人工标注：
  - 生成结果的可视化
  - 现在有两个各200行左右的已经完成标注的文件
  - 请据此给出对应的完整代码修改方案，随后将这个过程部署在python能够运行好的环境
  - 这个区间值反映的是用fasttext预测的相关性系数而非BertForNextSentencePrediction的
  - 现在要求用训练完成的fasttext生成第七列related_ft，这列存的仍然是related的[0,1]区间值
  - 请评估如上五步工作流的合理性，并提出你的建议和意见，必要时用代码实例和效果演示给出答案看
  - 现在要求加入人工判定的第八列related_classes_ft，但不是仅根据指定阈值来标注，而是主观判断
  - 最后是tieba_name, source, ask_content, answer_content, related, related_classes这几列

（二）FastText




- FastText有监督训练及自迭代：
（1）确保BERT标记完成的数据能被fasttext识别
（2）在每一轮自迭代中，以如下方式更新训练和原数据集
  - 由于贴吧问答数据的解释性，大部分数据标0即正样本
  - 将正样本与负样本之差的绝对值作为每次对原数据集随机采样的样本数，无论正负
  - 随机采样的问答对，问与答的顺序被打乱重新组合，但标签一律标1即为简单负样本
  - 将这个重新组合的问答对与原数据集合并，交给持有上一轮参数的fasttext进行训练
  - 这套持有新参数的fasttext被用于预测原数据集；原数据集的标签更新后，将它和这一轮用于训练的这个数据集一起生成下

（1）分词
- 没对ask_content和answer_content做分词，每轮自迭代数据量没有变化。。
- 不是因为每行数据大小不一样，而是因为什么别的原因吗？加入切分的表示符号也改下
- 如果你用的都是默认切分词，怎么知道他切分的后果好还是不好？请融合多种nlp指标评估给代码

（2）作图
- 上一轮的树状图画出来有点问题：只有0和1
- 横轴应该是以0.1为步长，把0到1均等分成十个区间，对相关系数的回归值做分类
- 纵轴的单位应该是完整写出它的量级，而不是用带小数点的数值乘以幂的系数，做统计
- 每个柱的最顶上的标签是该区间的样本量，并以不同的颜色区分开每个区间中所有的样本

（3）以此完成一轮数据自迭代，如此迭代20轮并作图：
  - 横轴为贴吧名字，例如"aiouniya"和"kangyabeiguo"
  - 写明当前轮自迭代的训练集样本数、贴吧名字和所取单位
  - 统计每次fasttext，在原数据集上预测的正负样本标签分布
  - 纵轴为最大取整标签数量，例如"liyi"有1428576行数据则纵轴取1500000
  - 以独立不同分布的观点，从所有迭代中选择一轮数据两极化最大的，再选择最后一轮迭代的结果保存，以此制作两张趋势图并存到logs/文件夹下
（4）*加权计算数据样本的留存率：
  - 例如"sunxiaochuan"一开始有7142856行数据后来变成4285719，则留存率为4285719/7142856~=0.6000000756
